{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40da419b",
   "metadata": {},
   "source": [
    "# COVID-19 Outcome Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26b52b",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "MLP\n",
    "\n",
    "- Data analysis\n",
    "- Data preprocessing and normalization\n",
    "- Data split\n",
    "- Configuration\n",
    "- Experiment tracking\n",
    "- Experiments - meaningful based on the results of previous experiments\n",
    "- Including improvement techniques (e.g. Dropout, Normalization layers, Skip Connections, Bottleneck Layers, …)\n",
    "- Hyperparameter search (grid/random) / sweep #optional\n",
    "- Results and evaluation metrics\n",
    "- Clear code\n",
    "- Markdown documentation and comments\n",
    "- Final presentation of projects\n",
    "- Effort on consultations\n",
    "\n",
    "# OUR TODO:\n",
    "\n",
    "- download dataset using pandas ? easier because of we can just use link but maybe everyone will use pandas -done\n",
    "- good enough data analysis that is seen in jupyter notebook, not just from reading dataset - done\n",
    "- correlation chart - chart of correlation of columns between themselves - done\n",
    "- outliers - what to do with them ?\n",
    "- counts of data in each column and plots of them -done\n",
    "- normalize age 0-1 young/old ? min max or z score, mean have 0 deviation has 1\n",
    "- warning if something has 100% correlation we should do something with it\n",
    "- better -1 is False; 0 - not state /dont know; 1 - True\n",
    "- think about combining weird features or if 20% are not state try to remove them\n",
    "- vantby tracking experiments\n",
    "- focus on binary prediction with binary cross entropy on only testing (zamerane na binarnu predikciu binary cross entropy na testovacej dat metriky netrenujem )\n",
    "- datasplit for training validation and testing DF 70 10 20 and check if decreasing both training and validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40261e",
   "metadata": {},
   "source": [
    "End-to-end pipeline covering EDA, preprocessing, stratified splits, imbalance-aware PyTorch models, experiment tracking, and final evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa1991",
   "metadata": {},
   "source": [
    "All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1699ab",
   "metadata": {},
   "source": [
    "Define path to dataset, batch size for training and device (cuda for NVIDIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275cbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"dataset.csv\")\n",
    "BATCH_SIZE = 1024\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e79c1",
   "metadata": {},
   "source": [
    "Load and explore dataset: show shape, numeric columns, distributions, and correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Shape of dataset: {raw_df.shape}\")\n",
    "display(raw_df.head())\n",
    "\n",
    "numeric_df = raw_df.select_dtypes(include=[\"number\"])\n",
    "\n",
    "raw_df.info()\n",
    "display(raw_df.count(numeric_only=True).to_frame(name=\"count\"))\n",
    "print(\"Dataset shape:\", raw_df.shape)\n",
    "\n",
    "for col in numeric_df.columns:\n",
    "    series = numeric_df[col]\n",
    "    counts = series.value_counts(dropna=False).sort_index()\n",
    "    x = range(len(counts))\n",
    "    labels = counts.index.astype(str)\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.bar(x, counts.values, color=\"steelblue\", alpha=0.9, width=0.8)\n",
    "    plt.title(f\"Count per value — {col}\", fontsize=12, pad=8)\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    if len(labels) > 40:\n",
    "        step = max(1, len(labels) // 40)\n",
    "        plt.xticks(list(x)[::step], labels[::step], rotation=45, ha=\"right\")\n",
    "    else:\n",
    "        plt.xticks(x, labels, rotation=45, ha=\"right\")\n",
    "    plt.grid(True, linestyle=\"--\", axis=\"y\", alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "corr = numeric_df.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".1f\",\n",
    "    square=True,\n",
    "    linewidths=1,\n",
    "    cbar_kws={\"shrink\": 0.7, \"label\": \"Correlation\"}\n",
    ")\n",
    "plt.title(\"Correlation Heatmap of Numeric Attributes\", fontsize=14, pad=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c06d15",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1441826",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw_df.describe(include='all').transpose())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ce530",
   "metadata": {},
   "source": [
    "Create binary target (1 = COVID, 0 = No COVID) and visualize target and age distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_series = raw_df['CLASIFFICATION_FINAL'].isin([1, 2, 3]).astype(int)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "target_series.value_counts(normalize=True).mul(100).reindex([0, 1]).plot(\n",
    "    kind='bar', ax=axes[0], color=['steelblue', 'tomato']\n",
    ")\n",
    "axes[0].set_title('Target distribution (%)')\n",
    "axes[0].set_xlabel('HAS_COVID')\n",
    "axes[0].set_ylabel('Percent')\n",
    "\n",
    "age_sample = raw_df['AGE'].clip(0, 100)\n",
    "axes[1].hist(age_sample, bins=30, color='slategray', alpha=0.9)\n",
    "axes[1].set_title('Age distribution (trimmed 0-100)')\n",
    "axes[1].set_xlabel('Age')\n",
    "axes[1].set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b290a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = raw_df.select_dtypes(include=['number']).columns\n",
    "sample_for_corr = raw_df[numeric_cols].sample(n=min(2000, len(raw_df)), random_state=42)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(sample_for_corr.corr(), cmap='coolwarm', linewidths=0.1, center=0)\n",
    "plt.title('Correlation heatmap (raw numeric sample)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09604e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = raw_df.copy()\n",
    "print('Sample before preprocessing:')\n",
    "display(demo_df.iloc[:30])\n",
    "\n",
    "demo_df.columns = demo_df.columns.str.strip()\n",
    "demo_df.rename(columns={'DATE_DIED': 'DEAD'}, inplace=True)\n",
    "med_unit_original = demo_df['MEDICAL_UNIT'].copy()\n",
    "classif_original = demo_df['CLASIFFICATION_FINAL'].copy()\n",
    "\n",
    "demo_df['DEAD'] = np.where(demo_df['DEAD'] == '9999-99-99', 2, 1)\n",
    "demo_df.loc[demo_df['SEX'] == 1, 'PREGNANT'] = 0\n",
    "binary_cols = ['USMER','SEX','INTUBED','PNEUMONIA','PREGNANT','DIABETES','COPD','ASTHMA','INMSUPR','HIPERTENSION','OTHER_DISEASE','CARDIOVASCULAR','OBESITY','RENAL_CHRONIC','TOBACCO','ICU','DEAD']\n",
    "demo_df[binary_cols] = demo_df[binary_cols].replace(2, 0)\n",
    "demo_df[binary_cols] = demo_df[binary_cols].replace(97, 0.5)\n",
    "demo_df[binary_cols] = demo_df[binary_cols].replace(98, 0.5)\n",
    "demo_df['MEDICAL_UNIT'] = med_unit_original\n",
    "demo_df['CLASIFFICATION_FINAL'] = classif_original\n",
    "demo_df.rename(columns={'SEX': 'IS_MALE'}, inplace=True)\n",
    "demo_df['CLASIFFICATION_FINAL'] = demo_df['CLASIFFICATION_FINAL'].replace([1,2,3], 1)\n",
    "demo_df['CLASIFFICATION_FINAL'] = demo_df['CLASIFFICATION_FINAL'].replace([4,5,6,7], 0)\n",
    "demo_df.rename(columns={'CLASIFFICATION_FINAL': 'HAS_COVID'}, inplace=True)\n",
    "print('Sample after key preprocessing steps:')\n",
    "display(demo_df.iloc[:30])\n",
    "# Display purpose only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7167b",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adbc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function that we actually use\n",
    "def preprocess_data(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = frame.copy()  # work on a copy to avoid modifying the original dataframe\n",
    "\n",
    "    # Clean column names and rename gender column for clarity\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.rename(columns={\"SEX\": \"IS_MALE\"}, inplace=True)\n",
    "\n",
    "    # Keep only rows with valid COVID classification values (1–6)\n",
    "    valid = df[\"CLASIFFICATION_FINAL\"].isin([1, 2, 3, 4, 5, 6])\n",
    "    df = df.loc[valid].copy()\n",
    "\n",
    "    # Create binary column DEAD (1 = dead, 0 = alive)\n",
    "    df[\"DEAD\"] = np.where(df[\"DATE_DIED\"] == \"9999-99-99\", 0, 1)\n",
    "\n",
    "    # List of binary features (0/1 type)\n",
    "    binary_cols = [\n",
    "        \"USMER\", \"IS_MALE\", \"INTUBED\", \"PNEUMONIA\", \"PREGNANT\", \"DIABETES\", \"COPD\",\n",
    "        \"ASTHMA\", \"INMSUPR\", \"HIPERTENSION\", \"OTHER_DISEASE\", \"CARDIOVASCULAR\",\n",
    "        \"OBESITY\", \"RENAL_CHRONIC\", \"TOBACCO\", \"ICU\", \"DEAD\",\n",
    "    ]\n",
    "\n",
    "    # Replace invalid codes (97–99 etc.) with NaN to mark missing data\n",
    "    replace_map = {1: 1, 2: 0, 3: np.nan, 97: np.nan, 98: np.nan, 99: np.nan}\n",
    "    df[binary_cols] = df[binary_cols].replace(replace_map)\n",
    "\n",
    "    # Ensure males are never marked as pregnant\n",
    "    df.loc[df[\"IS_MALE\"] == 1, \"PREGNANT\"] = 0\n",
    "\n",
    "    # Create hospitalization flag: 1 = hospitalized, 0 = outpatient\n",
    "    df[\"IS_HOSPITALIZED\"] = df[\"PATIENT_TYPE\"].map({1: 0, 2: 1}).fillna(0)\n",
    "    df.drop(columns=[\"PATIENT_TYPE\"], inplace=True)\n",
    "\n",
    "    # Convert COVID classification (1–3 positive, 4–6 negative) into binary label\n",
    "    df[\"HAS_COVID\"] = df[\"CLASIFFICATION_FINAL\"].replace({1: 1, 2: 1, 3: 1, 4: 0, 5: 0, 6: 0})\n",
    "    df.drop(columns=[\"CLASIFFICATION_FINAL\", \"DATE_DIED\"], inplace=True)\n",
    "\n",
    "    # Fill missing binary values with median (usually 0 or 1)\n",
    "    df[binary_cols] = df[binary_cols].fillna(df[binary_cols].median())\n",
    "\n",
    "    # Define chronic condition columns\n",
    "    risk_cols = [\n",
    "        \"DIABETES\", \"COPD\", \"ASTHMA\", \"INMSUPR\", \"HIPERTENSION\",\n",
    "        \"OTHER_DISEASE\", \"CARDIOVASCULAR\", \"OBESITY\", \"RENAL_CHRONIC\",\n",
    "    ]\n",
    "\n",
    "    # Create aggregated health indicators\n",
    "    df[\"CHRONIC_COUNT\"] = df[risk_cols].sum(axis=1)              # number of chronic diseases\n",
    "    df[\"MULTI_MORBID\"] = (df[\"CHRONIC_COUNT\"] >= 2).astype(int)  # has 2+ chronic diseases\n",
    "    df[\"RISK_OBESE_SMOKER\"] = ((df[\"OBESITY\"] == 1) | (df[\"TOBACCO\"] == 1)).astype(int)  # obese or smoker\n",
    "\n",
    "    # Bucketize age into groups (0–30, 31–45, 46–60, 61–75, 76+)\n",
    "    df[\"AGE_BUCKET\"] = (\n",
    "        pd.cut(df[\"AGE\"], bins=[0, 30, 45, 60, 75, 120], labels=False, include_lowest=True)\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    # Normalize age using standard scaling (mean=0, std=1)\n",
    "    scaler = StandardScaler()\n",
    "    df[\"AGE\"] = scaler.fit_transform(df[[\"AGE\"]])\n",
    "\n",
    "    # One-hot encode medical unit column (convert category → binary columns)\n",
    "    df = pd.get_dummies(df, columns=[\"MEDICAL_UNIT\"], prefix=\"MED_UNIT\", drop_first=True)\n",
    "\n",
    "    # Drop any remaining missing values and reset index\n",
    "    df = df.dropna()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Return cleaned and fully preprocessed dataset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b809b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = preprocess_data(raw_df)\n",
    "print(f\"Processed shape: {model_df.shape}\")\n",
    "display(model_df.head())\n",
    "feature_cols = [col for col in model_df.columns if col != \"HAS_COVID\"]\n",
    "print(f\"Feature count: {len(feature_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_numeric = model_df.select_dtypes(include=['number'])\n",
    "corr_processed = processed_numeric.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(\n",
    "    corr_processed,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='.1f',\n",
    "    square=True,\n",
    "    linewidths=1,\n",
    "    cbar_kws={'shrink': 0.7, 'label': 'Correlation'}\n",
    ")\n",
    "plt.title('Correlation Heatmap after Preprocessing', fontsize=14, pad=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ff099",
   "metadata": {},
   "source": [
    "## Data split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train (70%), validation (10%), and test (20%) sets\n",
    "train_df, temp_df = train_test_split(\n",
    "    model_df,\n",
    "    test_size=0.3,                           # 30% goes to temp (val + test)\n",
    "    stratify=model_df[\"HAS_COVID\"],          # keep same class ratio across splits\n",
    "    random_state=42,                         # ensure reproducibility\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Split temp into validation (1/3 of temp = 10%) and test (2/3 of temp = 20%)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=2 / 3,\n",
    "    stratify=temp_df[\"HAS_COVID\"],\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Reset indices for clean dataframes\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Helper function to print class distribution info\n",
    "def describe_split(name, frame):\n",
    "    share = frame[\"HAS_COVID\"].mean() * 100\n",
    "    print(f\"{name:<10s} n={len(frame):,} | positive={share:.2f}% | negative={100 - share:.2f}%\")\n",
    "\n",
    "# Display dataset split summary\n",
    "print(\"Dataset splits:\")\n",
    "describe_split(\"Train\", train_df)\n",
    "describe_split(\"Val\", val_df)\n",
    "describe_split(\"Test\", test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9440c89",
   "metadata": {},
   "source": [
    "## Torch datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d179fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to PyTorch TensorDataset (features + labels)\n",
    "def frame_to_dataset(frame):\n",
    "    features = frame[feature_cols].to_numpy(dtype=np.float32)   # input features\n",
    "    labels = frame[\"HAS_COVID\"].to_numpy(dtype=np.float32)      # target labels\n",
    "    return TensorDataset(torch.from_numpy(features), torch.from_numpy(labels))\n",
    "\n",
    "# Create datasets for training, validation, and testing\n",
    "train_dataset = frame_to_dataset(train_df)\n",
    "val_dataset = frame_to_dataset(val_df)\n",
    "test_dataset = frame_to_dataset(test_df)\n",
    "\n",
    "# Compute class weights to handle imbalance (more weight for minority class)\n",
    "class_counts = train_df[\"HAS_COVID\"].value_counts().to_dict()\n",
    "weights = train_df[\"HAS_COVID\"].map(lambda value: 1.0 / class_counts[value]).to_numpy(dtype=np.float32)\n",
    "\n",
    "# Create a sampler for balanced batches during training\n",
    "sampler = WeightedRandomSampler(weights=torch.from_numpy(weights), num_samples=len(weights), replacement=True)\n",
    "\n",
    "# Build data loaders for efficient batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Calculate positive class weight for loss function (to handle imbalance)\n",
    "positive = float((train_df[\"HAS_COVID\"] == 1).sum())\n",
    "negative = float((train_df[\"HAS_COVID\"] == 0).sum())\n",
    "pos_weight_value = negative / max(positive, 1.0)\n",
    "\n",
    "# Define binary classification loss with class weight\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value], dtype=torch.float32, device=device))\n",
    "\n",
    "# Inspect one batch from the training loader\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"Sample batch → X: {sample_batch[0].shape}, y: {sample_batch[1].shape}, pos_weight={pos_weight_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d831c",
   "metadata": {},
   "source": [
    "## Model and helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788726ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple feedforward MLP for binary COVID classification\n",
    "class CovidMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim  # start with the input feature size\n",
    "\n",
    "        # build hidden layers based on config\n",
    "        for hidden in hidden_layers:\n",
    "            layers.append(nn.Linear(prev, hidden))      # dense layer\n",
    "            layers.append(nn.BatchNorm1d(hidden))       # helps stabilize training\n",
    "            layers.append(nn.ReLU())                    # non-linearity\n",
    "            layers.append(nn.Dropout(dropout))          # regularization\n",
    "            prev = hidden                               # next layer input = this layer output\n",
    "\n",
    "        # final output layer (1 neuron for binary classification)\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward pass through the network\n",
    "        return self.net(x).squeeze(1)  # remove extra dimension (batch, 1) → (batch,)\n",
    "\n",
    "\n",
    "# Calculate common metrics from probabilities\n",
    "def metrics_from_probs(probs, labels, threshold=0.5):\n",
    "    preds = (probs >= threshold).astype(int)  # turn probs into 0/1 predictions\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
    "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
    "        \"pr_auc\": average_precision_score(labels, probs),  # area under precision-recall curve\n",
    "    }\n",
    "\n",
    "    # how much recall we get when precision is at least 0.7\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(labels, probs)\n",
    "    mask = prec_curve >= 0.7\n",
    "    metrics[\"recall_at_70_precision\"] = float(rec_curve[mask].max()) if mask.any() else 0.0\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Run evaluation on val/test data and collect metrics\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()  # disable dropout, switch to eval mode\n",
    "    losses, probs, labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():  # no gradients needed for evaluation\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            logits = model(xb)             # forward pass\n",
    "            loss = criterion(logits, yb)   # compute loss\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # convert logits → probabilities and collect labels\n",
    "            probs.append(torch.sigmoid(logits).cpu())\n",
    "            labels.append(yb.cpu())\n",
    "\n",
    "    # merge all batches into full arrays\n",
    "    prob_array = torch.cat(probs).numpy()\n",
    "    label_array = torch.cat(labels).numpy()\n",
    "\n",
    "    # compute metrics\n",
    "    metrics = metrics_from_probs(prob_array, label_array)\n",
    "    metrics[\"roc_auc\"] = roc_auc_score(label_array, prob_array)\n",
    "    metrics[\"loss\"] = float(np.mean(losses))  # average val loss\n",
    "\n",
    "    return metrics, prob_array, label_array\n",
    "\n",
    "\n",
    "# Find the threshold that gives the best F1 score\n",
    "def find_best_threshold(probs, labels):\n",
    "    best_thr = 0.5\n",
    "    best_score = 0.0\n",
    "\n",
    "    # try thresholds from 0.1 to 0.9\n",
    "    for thr in np.linspace(0.1, 0.9, 17):\n",
    "        score = f1_score(labels, (probs >= thr).astype(int), zero_division=0)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thr = float(thr)\n",
    "\n",
    "    return best_thr, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    # Build model from config and move to device\n",
    "    model = CovidMLP(len(feature_cols), config[\"hidden_layers\"], config[\"dropout\"]).to(device)\n",
    "\n",
    "    # Optimizer: AdamW (Adam + decoupled weight decay for better generalization)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    # LR scheduler: reduce LR when validation loss plateaus (mode='min')\n",
    "    # factor=0.5 → halve LR; patience=1 → wait 1 epoch without improvement\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=1\n",
    "    )\n",
    "\n",
    "    # Initialize Weights & Biases run for experiment tracking\n",
    "    # - project: group runs\n",
    "    # - config: hyperparams logged as run config\n",
    "    # - reinit=False: reuse the same process/run context\n",
    "    wandb_run = wandb.init(project=\"covid-19\", config=config, reinit=False)\n",
    "    wandb_run.watch(model, log=\"all\")  # log gradients/weights for debugging\n",
    "\n",
    "    best_state = None            # best model weights (by val F1)\n",
    "    best_snapshot = None         # (metrics, probs, labels) for best epoch\n",
    "    best_score = -np.inf         # track best F1\n",
    "    history = []                 # per-epoch metrics for plotting\n",
    "\n",
    "    # ---- Training loop ----\n",
    "    for epoch in range(1, config[\"epochs\"] + 1):\n",
    "        model.train()            # enable dropout/batchnorm updates\n",
    "        epoch_losses = []\n",
    "\n",
    "        # Iterate mini-batches\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()                # reset accumulated grads\n",
    "            logits = model(xb)                   # forward pass → logits\n",
    "            loss = criterion(logits, yb)         # BCEWithLogitsLoss (with pos_weight)\n",
    "            loss.backward()                      # backpropagate gradients\n",
    "            optimizer.step()                     # update weights\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        # ---- Validation ----\n",
    "        val_metrics, val_probs, val_labels = evaluate_model(model, val_loader)\n",
    "\n",
    "        # Step LR scheduler with validation loss (expects a scalar)\n",
    "        scheduler.step(val_metrics[\"loss\"])\n",
    "\n",
    "        # Save epoch summary for later analysis/plots\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": float(np.mean(epoch_losses)),\n",
    "            **{k: v for k, v in val_metrics.items()},\n",
    "        })\n",
    "\n",
    "        # Console log\n",
    "        print(\n",
    "            f\"{config['name']:<10s} epoch {epoch:02d} \"\n",
    "            f\"train_loss={history[-1]['train_loss']:.3f} \"\n",
    "            f\"val_loss={val_metrics['loss']:.3f} \"\n",
    "            f\"val_f1={val_metrics['f1']:.3f}\"\n",
    "        )\n",
    "\n",
    "        # Log key metrics to W&B for dashboards/curves\n",
    "        wandb_run.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": float(np.mean(epoch_losses)),\n",
    "            \"val_loss\": val_metrics[\"loss\"],\n",
    "            \"val_f1\": val_metrics[\"f1\"],\n",
    "            \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
    "        })\n",
    "\n",
    "        # Track best model by validation F1\n",
    "        if val_metrics[\"f1\"] > best_score:\n",
    "            best_score = val_metrics[\"f1\"]\n",
    "            best_state = deepcopy(model.state_dict())                  # keep weights\n",
    "            best_snapshot = (val_metrics.copy(), val_probs.copy(),     # keep artifacts\n",
    "                             val_labels.copy())\n",
    "\n",
    "    # Restore best weights before returning\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    # Close W&B run cleanly\n",
    "    wandb_run.finish()\n",
    "\n",
    "    # Return trained (best) model, full training history, and best-epoch snapshot\n",
    "    return model, history, best_snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d2bcc",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca11e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small grid of experiments (architectures + hyperparameters)\n",
    "experiment_grid = [\n",
    "    {\"name\": \"baseline\", \"hidden_layers\": [128, 64, 32], \"dropout\": 0.3, \"lr\": 3e-4, \"weight_decay\": 1e-4, \"epochs\": 10},\n",
    "    {\"name\": \"compact\",  \"hidden_layers\": [64, 32],       \"dropout\": 0.25, \"lr\": 5e-4, \"weight_decay\": 5e-5, \"epochs\": 12},\n",
    "    {\"name\": \"wide\",     \"hidden_layers\": [256, 128, 64], \"dropout\": 0.4,  \"lr\": 2e-4, \"weight_decay\": 1e-4, \"epochs\": 12},\n",
    "]\n",
    "\n",
    "experiment_results = []  # will store trained model snapshots + metrics for each config\n",
    "\n",
    "# Run training for each config in the grid\n",
    "for cfg in experiment_grid:\n",
    "    model, history, snapshot = train_model(cfg)  # train and return best-epoch snapshot\n",
    "    metrics_at_05, val_probs, val_labels = snapshot  # metrics at 0.5 threshold + raw probs/labels\n",
    "\n",
    "    # Tune decision threshold to maximize F1 on validation set\n",
    "    best_thr, _ = find_best_threshold(val_probs, val_labels)\n",
    "\n",
    "    # Recompute metrics using the tuned threshold (keep ROC AUC & loss from snapshot)\n",
    "    tuned_metrics = metrics_from_probs(val_probs, val_labels, threshold=best_thr)\n",
    "    tuned_metrics[\"roc_auc\"] = metrics_at_05[\"roc_auc\"]\n",
    "    tuned_metrics[\"loss\"] = metrics_at_05[\"loss\"]\n",
    "\n",
    "    # Save experiment artifacts for later comparison / model selection\n",
    "    experiment_results.append(\n",
    "        {\n",
    "            \"name\": cfg[\"name\"],                     # experiment label\n",
    "            \"config\": cfg,                           # full hyperparameter config\n",
    "            \"state_dict\": deepcopy(model.state_dict()),  # best model weights\n",
    "            \"threshold\": best_thr,                   # tuned decision threshold\n",
    "            \"val_metrics\": tuned_metrics,            # metrics at tuned threshold\n",
    "            \"history\": history,                      # per-epoch training/val history\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Build a compact comparison table across experiments\n",
    "results_table = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"experiment\": result[\"name\"],\n",
    "            \"val_f1\": result[\"val_metrics\"][\"f1\"],\n",
    "            \"val_pr_auc\": result[\"val_metrics\"][\"pr_auc\"],\n",
    "            \"val_recall_at_70_precision\": result[\"val_metrics\"][\"recall_at_70_precision\"],\n",
    "            \"threshold\": result[\"threshold\"],\n",
    "        }\n",
    "        for result in experiment_results\n",
    "    ]\n",
    ").sort_values(by=\"val_f1\", ascending=False)  # rank by F1\n",
    "\n",
    "print(\"Validation summary:\")\n",
    "display(results_table.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for each experiment (train loss, val loss, F1 across epochs)\n",
    "history_metrics = [\"train_loss\", \"loss\", \"f1\"]\n",
    "\n",
    "for result in experiment_results:\n",
    "    history_df = pd.DataFrame(result[\"history\"])  # convert per-epoch metrics to DataFrame\n",
    "    plt.figure(figsize=(7, 4))\n",
    "\n",
    "    # Plot selected metrics if present\n",
    "    for metric in history_metrics:\n",
    "        if metric in history_df.columns:\n",
    "            plt.plot(history_df[\"epoch\"], history_df[metric], label=metric.replace(\"_\", \" \"))\n",
    "\n",
    "    plt.title(f\"Training history - {result['name']}\")  # experiment name\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2fd4e",
   "metadata": {},
   "source": [
    "## Test evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b123fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best experiment by highest validation F1\n",
    "best_experiment = max(experiment_results, key=lambda item: item[\"val_metrics\"][\"f1\"])\n",
    "best_cfg = best_experiment[\"config\"]           # best hyperparameters\n",
    "best_threshold = best_experiment[\"threshold\"]  # tuned decision threshold (from val set)\n",
    "\n",
    "# Recreate the best model architecture and load its saved weights\n",
    "best_model = CovidMLP(len(feature_cols), best_cfg[\"hidden_layers\"], best_cfg[\"dropout\"]).to(device)\n",
    "best_model.load_state_dict(best_experiment[\"state_dict\"])\n",
    "\n",
    "# Evaluate on the held-out test set\n",
    "test_metrics_raw, test_probs, test_labels = evaluate_model(best_model, test_loader)\n",
    "\n",
    "# Recompute metrics with the tuned threshold (keep ROC AUC & loss from raw eval)\n",
    "test_metrics = metrics_from_probs(test_probs, test_labels, threshold=best_threshold)\n",
    "test_metrics[\"roc_auc\"] = test_metrics_raw[\"roc_auc\"]\n",
    "test_metrics[\"loss\"] = test_metrics_raw[\"loss\"]\n",
    "\n",
    "# Pretty-print main test metrics\n",
    "print(\"Test metrics with tuned threshold:\")\n",
    "for key in [\"loss\", \"roc_auc\", \"pr_auc\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"recall_at_70_precision\"]:\n",
    "    print(f\"  {key}: {test_metrics[key]:.4f}\")\n",
    "\n",
    "# Derive hard predictions using tuned threshold, then print a detailed classification report\n",
    "binary_preds = (test_probs >= best_threshold).astype(int)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(test_labels, binary_preds, digits=4, zero_division=0))\n",
    "\n",
    "# Confusion matrix (as a DataFrame for nicer display)\n",
    "cm = confusion_matrix(test_labels, binary_preds)\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "print(\"Confusion matrix:\")\n",
    "display(cm_df)\n",
    "\n",
    "# Log confusion matrix to Weights & Biases for the best config\n",
    "wandb_run = wandb.init(project=\"covid-19\", config=best_cfg, reinit=True)  # new run for test artifacts\n",
    "wandb_run.log({\n",
    "    \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "        preds=binary_preds.tolist(),\n",
    "        y_true=test_labels.tolist(),\n",
    "        title=\"Confusion Matrix of best Model\"\n",
    "    )\n",
    "})\n",
    "wandb_run.finish()\n",
    "\n",
    "# Plot Precision-Recall curve with the chosen operating point highlighted\n",
    "precisions, recalls, _ = precision_recall_curve(test_labels, test_probs)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(recalls, precisions, label=\"PR curve\")\n",
    "plt.scatter(test_metrics[\"recall\"], test_metrics[\"precision\"], color=\"red\", label=\"Chosen threshold\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Test precision-recall curve\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
